[Response Selectors](retrieval-actions.mdx) are now trained on retrieval intent labels by default instead of the actual response text. For most models, this should improve training time and accuracy of the `ResponseSelector`.

If you want to revert to the pre-2.0 default behavior, add the `use_text_as_label=true` parameter to your `ResponseSelector` component.

You can now also have multiple response templates for a single sub-intent of a retrieval intent. The first response template
containing the text attribute is picked for training(if `use_text_as_label=True`) and a random template is picked for bot's utterance just as how other `utter_` templates are picked.

All response selector related evaluation artifacts - `report.json, successes.json, errors.json, confusion_matrix.png` now use the sub-intent of the retrieval intent as the target and predicted labels instead of the actual response text.

The output schema of `ResponseSelector` has changed - `full_retrieval_intent` and `name` have been deprecated in favour 
of `intent_response_key` and `response_templates` respectively. Additionally a key `all_retrieval_intents` 
is added to the response selector output which will hold a list of all retrieval intents(faq,chitchat, etc.) 
that are present in the training data.An example output looks like this - 
```
"response_selector": {
    "all_retrieval_intents": ["faq"],
    "default": {
      "response": {
        "id": 1388783286124361986, "confidence": 1.0, "intent_response_key": "faq/is_legit",
        "response_templates": [
          {
            "text": "absolutely",
            "image": "https://i.imgur.com/nGF1K8f.jpg"
          },
          {
            "text": "I think so."
          }
        ],
      },
      "ranking": [
        {
          "id": 1388783286124361986,
          "confidence": 1.0,
          "intent_response_key": "faq/is_legit"
        },
      ]
```

An example bot demonstrating how to use the `ResponseSelector` is added to the `examples` folder.